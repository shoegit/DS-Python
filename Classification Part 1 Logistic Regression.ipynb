{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Classification Part 1: Logistic Regression\n",
    "\n",
    "_Authors: Kiefer Katovich, Matt Brems, Noelle Brown, Ng Shu Min_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Distinguish between regression and classification problems.\n",
    "- Understand how logistic regression is similar to and different from linear regression.\n",
    "- Fit, generate predictions from, and evaluate a logistic regression model in `sklearn`.\n",
    "- Understand how to interpret the coefficients of logistic regression.\n",
    "- Know the benefits of logistic regression as a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "---\n",
    "\n",
    "Logistic regression is a natural bridge to connect regression and classification.\n",
    "- Logistic regression is the most common binary classification algorithm.\n",
    "- Because it is a regression model, logistic regression will predict continuous values.\n",
    "    - Logistic regression will predict continuous probabilities between 0 and 1.\n",
    "    - Example: What is the probability that someone shows up to vote?\n",
    "- However, logistic regression almost always operates as a classification model.\n",
    "    - Logistic regression will use these continuous predictions to classify something as 0 or 1.\n",
    "    - Example: Based on the predicted probability, do we predict that someone votes?\n",
    "\n",
    "In this lecture, we'll only be reviewing the binary outcome case with two classes, but logistic regression can be generalized to predicting outcomes with 3 or more classes.\n",
    "\n",
    "**Some examples of when logistic regression could be used:**\n",
    "- Will a user will purchase a product, given characteristics like income, age, and number of family members?\n",
    "- Does this patient have a specific disease based on their symptoms?\n",
    "- Will a person default on their loan?\n",
    "- Is the iris flower in front of me an \"*Iris versicolor*?\"\n",
    "- Given one's GPA and the prestige of a college, will a student be admitted to a specific graduate program?\n",
    "\n",
    "And many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate School Admissions\n",
    "\n",
    "---\n",
    "\n",
    "Today, we'll be applying logistic regression to solve the following problem: \"Given one's GPA, will a student be admitted to a specific graduate program?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data.\n",
    "admissions = pd.read_csv('datasets/grad_admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first five rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are:\n",
    "- `admit`: A binary 0/1 variable indicating whether or not a student was admitted, where 1 means admitted and 0 means not admitted.\n",
    "- `gre`: The student's [GRE (Graduate Record Exam)](https://en.wikipedia.org/wiki/Graduate_Record_Examinations) score.\n",
    "- `gpa`: The student's GPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missing values do we have in each column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every row that has an NA (set inplace=True).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What assumption are we making when we drop rows that have at least one NA in it?</summary>\n",
    "    \n",
    "- We assume that what we drop looks like what we have observed. That is, there's nothing special about the rows we happened to drop.\n",
    "- We might say that what we dropped is a random sample of our whole data.\n",
    "- It's not important to know this now, but the formal term is that our data is missing completely at random.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's have a look at the data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scatter plot to compare the independent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it look like there is a correlation? \n",
    "admissions['gre'].corr(admissions['gpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram to compare the distribution of the numeric variables\n",
    "admissions.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram to check distribution of gre by admit values\n",
    "sns.histplot(admissions, x='gre',hue='admit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly create a histogram for gpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a clearer relationship between gpa and the value of admit. Let's try to perform the classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of Notation\n",
    "\n",
    "You're quite familiar with **linear** regression:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\hat{\\mathbf{y}} &=& \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + \\hat{\\beta}_2x_2 + \\cdots + \\hat{\\beta}_px_p \\\\\n",
    "&=& \\hat{\\beta}_0 + \\sum_{j=1}^p\\hat{\\beta}_jX_j\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\hat{\\mathbf{y}}$ is the predicted values of $\\mathbf{y}$ based on all of the inputs $x_j$.\n",
    "- $x_1$, $x_2$, $\\ldots$, $x_p$ are the predictors.\n",
    "- $\\hat{\\beta}_0$ is the estimated intercept.\n",
    "- $\\hat{\\beta}_j$ is the estimated coefficient for the predictor $x_j$, the $j$th column in variable matrix $X$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot-reg'></a>\n",
    "### What if we predicted `admit` with `gpa` using Linear Regression?\n",
    "\n",
    "Looking at the plot below, what are problems with using a regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot admissions vs. gpa and line of best fit\n",
    "plt.figure(figsize = (12, 5))\n",
    "sns.regplot(x= admissions['gpa'], y= admissions['admit'], data= admissions,\n",
    "            ci = False, scatter_kws = {'s': 2},\n",
    "            line_kws = {'color': 'orange'})\n",
    "plt.ylim(-0.1, 1.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pred-binary'></a>\n",
    "\n",
    "## Predicting a Binary Class\n",
    "\n",
    "---\n",
    "\n",
    "In our case we have two classes: `1=admitted` and `0=rejected`.\n",
    "\n",
    "The logistic regression is still solving for $\\hat{y}$. However, in our binary classification case, $\\hat{y}$ will be the probability of $y$ being one of the classes.\n",
    "\n",
    "$$\n",
    "\\hat{y} = P(y = 1)\n",
    "$$\n",
    "\n",
    "We'll still try to fit a \"line\" of best fit to this... except it won't be perfectly linear. We need to *guarantee* that the right-hand side of the regression equation will evaluate to a probability. (That is, some number between 0 and 1!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with the logistic regression model.\n",
    "\n",
    "We can follow the same steps to build a logistic regression model that we follow to build a linear regression model.\n",
    "\n",
    "1. Define X & y\n",
    "2. Instantiate the model.\n",
    "3. Fit the model.\n",
    "4. Generate predictions.\n",
    "5. Evaluate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split into training & testing sets, using only 'gpa' as the independent variable and 'admit' as the target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Instantiate our model.\n",
    "logreg=LogisticRegression()\n",
    "# Step 3: Fit our model.\n",
    "\n",
    "\n",
    "# get the intercept and coefficient parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods in `sklearn` to be aware of when using logistic regression:\n",
    "- `.predict()`\n",
    "- `.predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 (part 1): Generate predicted values on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 (part 2): Generate predicted probabilities on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How would you interpret the predict_proba() output?</summary>\n",
    "    \n",
    "- This shows the probability of being rejected ($P(Y=0)$) and the probability of being admitted ($P(Y=1)$) for each observation in the testing dataset.\n",
    "- The first array, corresponds to the first testing observation.\n",
    "    - The `.predict()` value for this observation is 0. This is because $P(Y=0) > P(Y=1)$.\n",
    "- The second array, corresponds to the second testing observation.\n",
    "    - The `.predict()` value for this observation is 0. This is because $P(Y=0) > P(Y=1)$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing logistic regression probabilities.\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.scatter(X_test, y_test, s = 10);\n",
    "\n",
    "plt.plot(X_test.sort_values('gpa'),\n",
    "         logreg.predict_proba(X_test.sort_values('gpa'))[:,1],\n",
    "         color = 'grey', alpha = 0.8, lw = 3)\n",
    "\n",
    "plt.xlabel('GPA')\n",
    "plt.ylabel('Admit')\n",
    "plt.title('Predicting Admission from GPA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate model using the score() method on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate model using the score() method on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `.score()` method for classification models gives us the accuracy score.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Accuracy} = \\frac{\\text{number of correct predictions}}{\\text{number of total predictions}}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Remind me: what does .score() tell me for a regression model?</summary>\n",
    "    \n",
    "- The $R^2$ score.\n",
    "- Remember that $R^2$ is the proportion of variance in our $Y$ values that are explained by our model.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the log-odds —the natural logarithm of the odds.\n",
    "\n",
    "The combination of converting the \"probability of success\" to \"odds of success,\" then taking the logarithm of that is called the **logit link function**.\n",
    "\n",
    "$$\n",
    "\\text{logit}\\big(P(y=1)\\big) = \\log\\bigg(\\frac{P(y=1)}{1-P(y=1)}\\bigg) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p\n",
    "$$\n",
    "\n",
    "We've bent our line how we want... but how do we interpret our coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odds\n",
    "\n",
    "Probabilities and odds represent the same thing in different ways. The odds for probability **p** is defined as:\n",
    "\n",
    "$$\n",
    "\\text{odds}(p) = \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "The odds of a probability is a measure of how many times as likely an event is to happen than it is to not happen.\n",
    "\n",
    "**Example**: Suppose I'm looking at the probability and odds of a specific horse, \"Secretariat,\" winning a race.\n",
    "\n",
    "- When **`p = 0.5`**: **`odds = 1`**\n",
    "    - The horse Secretariat is as likely to win as it is to lose.\n",
    "- When **`p = 0.75`**: **`odds = 3`**\n",
    "    - The horse Secretariat is three times as likely to win as it is to lose.\n",
    "- When **`p = 0.40`**: **`odds = 0.666..`**\n",
    "   - The horse Secretariat is two-thirds as likely to win as it is to lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting a one-unit change in $x_i$.\n",
    "\n",
    "$$\\log\\bigg(\\frac{P(y=1)}{1-P(y=1)}\\bigg) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p$$\n",
    "\n",
    "Given this model, a one-unit change in $x_i$ implies a $\\beta_i$ unit change in the log odds of success.\n",
    "\n",
    "**This is annoying**.\n",
    "\n",
    "We often convert log-odds back to \"regular odds\" when interpreting our coefficient... our mind understands odds better than the log of odds.\n",
    "\n",
    "**(BONUS)** So, let's get rid of the log on the left-hand side. Mathematically, we do this by \"exponentiating\" each side.\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\log\\bigg(\\frac{P(y=1)}{1-P(y=1)}\\bigg) &=& \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p \\\\\n",
    "\\Rightarrow e^{\\Bigg(\\log\\bigg(\\frac{P(y=1)}{1-P(y=1)}\\bigg)\\Bigg)} &=& e^{\\Bigg(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p\\Bigg)} \\\\\n",
    "\\Rightarrow \\frac{P(y=1)}{1-P(y=1)} &=& e^{\\Bigg(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p\\Bigg)} \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "**Interpretation**: A one-unit change in $x_i$ means that success is $e^{\\beta_i}$ times as likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> I want to interpret the coefficient $\\hat{\\beta}_1$ for my logistic regression model. How would I interpret this coefficient?</summary>\n",
    "    \n",
    "- Our model is that $\\log\\bigg(\\frac{P(admit=1)}{1-P(admit=1)}\\bigg) = \\beta_0 + \\beta_1\\text{GPA}$.\n",
    "- As GPA increases by 1, the log-odds of someone being admitted increases by 4.92.\n",
    "- As GPA increases by 1, someone is $e^{4.92}$ times as likely to be admitted.\n",
    "- As GPA increases by 1, someone is about 137.06 times as likely to be admitted to grad school.\n",
    "</details>\n",
    "\n",
    "> Hint: Use the [np.exp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the np.exp function to calculate the odds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "Let's save the model in a pickle file to be used in the next notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the best model (decreg3) , and store it in file as a pickle format, .pkl\n",
    "import pickle\n",
    "\n",
    "filename = 'admissions_log_reg.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(logreg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test sets too for evaluation later\n",
    "X_test.to_csv('admissions_X_test.csv')\n",
    "y_test.to_csv('admissions_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "The goal of logistic regression is to find the best-fitting model to describe the relationship between a binary outcome and a set of independent variables.\n",
    "\n",
    "Logistic regression generates the coefficients of a formula to predict a logit transformation of the probability that the characteristic of interest is present.\n",
    "\n",
    "The coefficients are interpreted in terms of the odds of the event, where a one-unit change in the value of the independent variable with coefficient ${\\beta}$ will increase the odds by $e^{\\beta}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
